{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/mnt/user-home/git/nesdatapipeline')\n",
    "sys.path.insert(0,'/mnt/user-home/git/nes')\n",
    "#sys.path.insert(0,'/mnt/user-home/git/nes')\n",
    "from lyft_fugue_lyft import LLK8sRunner\n",
    "from nesdatapipeline.tasks import *\n",
    "from nesdatapipeline.constants import *\n",
    "SPARK_CONFIG_SAMPLING['fugue.cluster.size']='128*8*64g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "CONTINUOUS_FEATURES = [\n",
    "                    'shortwait_cancel_no_expectation_missed_r7',\n",
    "                    'mediumwait_cancel_no_expectation_missed_r7',\n",
    "                    'largewait_cancel_no_expectation_missed_r7',\n",
    "                    'shortwait_match_no_expectation_missed_r7',\n",
    "                    'mediumwait_match_no_expectation_missed_r7',\n",
    "                    'largewait_match_no_expectation_missed_r7',\n",
    "                    'shortwait_lapse_no_expectation_missed_r7',\n",
    "                    'mediumwait_lapse_no_expectation_missed_r7',\n",
    "                    'largewait_lapse_no_expectation_missed_r7',\n",
    "                    'shortwait_cancel_small_expectation_missed_r7',\n",
    "                    'mediumwait_cancel_small_expectation_missed_r7',\n",
    "                    'largewait_cancel_small_expectation_missed_r7',\n",
    "                    'shortwait_match_small_expectation_missed_r7',\n",
    "                    'mediumwait_match_small_expectation_missed_r7',\n",
    "                    'largewait_match_small_expectation_missed_r7',\n",
    "                    'shortwait_lapse_small_expectation_missed_r7',\n",
    "                    'mediumwait_lapse_small_expectation_missed_r7',\n",
    "                    'largewait_lapse_small_expectation_missed_r7',\n",
    "                    'shortwait_cancel_large_expectation_missed_r7',\n",
    "                    'mediumwait_cancel_large_expectation_missed_r7',\n",
    "                    'largewait_cancel_large_expectation_missed_r7',\n",
    "                    'shortwait_match_large_expectation_missed_r7',\n",
    "                    'mediumwait_match_large_expectation_missed_r7',\n",
    "                    'largewait_match_large_expectation_missed_r7',\n",
    "                    'shortwait_lapse_large_expectation_missed_r7',\n",
    "                    'mediumwait_lapse_large_expectation_missed_r7',\n",
    "                    'largewait_lapse_large_expectation_missed_r7',\n",
    "                    'shortwait_cancel_no_expectation_missed_r14',\n",
    "                    'mediumwait_cancel_no_expectation_missed_r14',\n",
    "                    'largewait_cancel_no_expectation_missed_r14',\n",
    "                    'shortwait_match_no_expectation_missed_r14',\n",
    "                    'mediumwait_match_no_expectation_missed_r14',\n",
    "                    'largewait_match_no_expectation_missed_r14',\n",
    "                    'shortwait_lapse_no_expectation_missed_r14',\n",
    "                    'mediumwait_lapse_no_expectation_missed_r14',\n",
    "                    'largewait_lapse_no_expectation_missed_r14',\n",
    "                    'shortwait_cancel_small_expectation_missed_r14',\n",
    "                    'mediumwait_cancel_small_expectation_missed_r14',\n",
    "                    'largewait_cancel_small_expectation_missed_r14',\n",
    "                    'shortwait_match_small_expectation_missed_r14',\n",
    "                    'mediumwait_match_small_expectation_missed_r14',\n",
    "                    'largewait_match_small_expectation_missed_r14',\n",
    "                    'shortwait_lapse_small_expectation_missed_r14',\n",
    "                    'mediumwait_lapse_small_expectation_missed_r14',\n",
    "                    'largewait_lapse_small_expectation_missed_r14',\n",
    "                    'shortwait_cancel_large_expectation_missed_r14',\n",
    "                    'mediumwait_cancel_large_expectation_missed_r14',\n",
    "                    'largewait_cancel_large_expectation_missed_r14',\n",
    "                    'shortwait_match_large_expectation_missed_r14',\n",
    "                    'mediumwait_match_large_expectation_missed_r14',\n",
    "                    'largewait_match_large_expectation_missed_r14',\n",
    "                    'shortwait_lapse_large_expectation_missed_r14',\n",
    "                    'mediumwait_lapse_large_expectation_missed_r14',\n",
    "                    'largewait_lapse_large_expectation_missed_r14',\n",
    "                    'shortwait_cancel_no_expectation_missed_r28',\n",
    "                    'mediumwait_cancel_no_expectation_missed_r28',\n",
    "                    'largewait_cancel_no_expectation_missed_r28',\n",
    "                    'shortwait_match_no_expectation_missed_r28',\n",
    "                    'mediumwait_match_no_expectation_missed_r28',\n",
    "                    'largewait_match_no_expectation_missed_r28',\n",
    "                    'shortwait_lapse_no_expectation_missed_r28',\n",
    "                    'mediumwait_lapse_no_expectation_missed_r28',\n",
    "                    'largewait_lapse_no_expectation_missed_r28',\n",
    "                    'shortwait_cancel_small_expectation_missed_r28',\n",
    "                    'mediumwait_cancel_small_expectation_missed_r28',\n",
    "                    'largewait_cancel_small_expectation_missed_r28',\n",
    "                    'shortwait_match_small_expectation_missed_r28',\n",
    "                    'mediumwait_match_small_expectation_missed_r28',\n",
    "                    'largewait_match_small_expectation_missed_r28',\n",
    "                    'shortwait_lapse_small_expectation_missed_r28',\n",
    "                    'mediumwait_lapse_small_expectation_missed_r28',\n",
    "                    'largewait_lapse_small_expectation_missed_r28',\n",
    "                    'shortwait_cancel_large_expectation_missed_r28',\n",
    "                    'mediumwait_cancel_large_expectation_missed_r28',\n",
    "                    'largewait_cancel_large_expectation_missed_r28',\n",
    "                    'shortwait_match_large_expectation_missed_r28',\n",
    "                    'mediumwait_match_large_expectation_missed_r28',\n",
    "                    'largewait_match_large_expectation_missed_r28',\n",
    "                    'shortwait_lapse_large_expectation_missed_r28',\n",
    "                    'mediumwait_lapse_large_expectation_missed_r28',\n",
    "                    'largewait_lapse_large_expectation_missed_r28',\n",
    "                    'sessions_r28','ride_intents_r28','ride_requests_r28',\n",
    "                    'conversion_r28','eta_r28','pt_incidence_r28','pt_r28',\n",
    "                    'sessions_r14','ride_intents_r14','ride_requests_r14',\n",
    "                    'conversion_r14','eta_r14','pt_incidence_r14','pt_r14',\n",
    "                    'sessions_r7','ride_intents_r7','ride_requests_r7',\n",
    "                    'conversion_r7','eta_r7','pt_incidence_r7','pt_r7',\n",
    "                     'local_hr_of_week',\n",
    "                    'days_since_activation',\n",
    "                    'bookings_usd_r7','bookings_usd_r14','bookings_usd_r28',\n",
    "                    'net_revenue_usd_r7','net_revenue_usd_r14','net_revenue_usd_r28',\n",
    "                    'rider_first_lng','rider_first_lat','rider_last_lng','rider_last_lat','ride_cancels_r14',\n",
    "                    'ride_a1ks_r14','ride_cancels_r7','ride_a1ks_r7','ride_cancels_r28','ride_a1ks_r28']\n",
    "\n",
    "\n",
    "TARGET_ENCODE_FEATURES=['region']\n",
    "ONEHOT_ENCODE_FEATURES=[\n",
    "    \n",
    "        \"density_category\",\n",
    "        \"hour_types\",\n",
    "        \"user_type\",\n",
    "        \"analytical_ride_type\",\n",
    "    ]\n",
    "continuous_features=json.dumps(CONTINUOUS_FEATURES)\n",
    "target_features=json.dumps(TARGET_ENCODE_FEATURES)\n",
    "onehot_features=json.dumps(ONEHOT_ENCODE_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the training data for your treatment configuration gets stored. \n",
    "TRAINING_DATA_PATH = \"s3://lyft-fugue-cache/expire/30d/nes_v2_matching/train\"\n",
    "\n",
    "# Where the data you wish to predict on will be stored. \n",
    "PREDICTION_DATA_PATH = \"s3://lyft-fugue-cache/expire/30d/nes_v2_matching/prediction\"\n",
    "\n",
    "# The final output predictions/scores. \n",
    "PREDICTION_OUTPUT_DATA_PATH = \"s3://lyft-fugue-cache/expire/30d/nes_v2_matching/prediction_output\"\n",
    "\n",
    "# The path the serialized model gets saved to.\n",
    "MODEL_PATH = \"s3://lyft-fugue-cache/expire/30d/nes_v2_matching/model\"\n",
    "\n",
    "# The table you've generated for training. Should include your confounding variables along with the outcome and\n",
    "# experiences you wish to measure. \n",
    "\n",
    "SAMPLING_SOURCE_TABLE = 'yibeil.matching_nes_final2'\n",
    "\n",
    "#SAMPLING_SOURCE_TABLE = 'base.nes_v2_final'\n",
    "# The configuration file for your treatments. See https://github.com/lyft/nesdatapipeline for more details. \n",
    "treatment_group_config_path='s3://data-team/yibeil/matching_nes_treatment.json'\n",
    "#treatment_group_config_path='s3://data-team/dgoldman/nes_treatments/nesv2_9.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAINING_SAMPLE_SIZE = 1000\n",
    "EVALUATION_TEST_PCT = 0.2\n",
    "EVALUATION_FOLD = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_cancel_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*3486189<1000 AND  shortwait_cancel_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_cancel_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*40276570<1000 AND  shortwait_match_no_expectation_missed = 1 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_cancel_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*5600462<1000 AND  mediumwait_cancel_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_cancel_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*40276570<1000 AND  shortwait_match_no_expectation_missed = 1 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_cancel_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*3085364<1000 AND  largewait_cancel_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_cancel_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*40276570<1000 AND  shortwait_match_no_expectation_missed = 1 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_match_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*20330229<1000 AND  mediumwait_match_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_match_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 2 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_match_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*5267340<1000 AND  largewait_match_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_match_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 3 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_lapse_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE TRUE AND  shortwait_lapse_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_lapse_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 3 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_lapse_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE TRUE AND  mediumwait_lapse_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_lapse_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 4 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_lapse_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*3132165<1000 AND  largewait_lapse_no_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_lapse_no_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 4 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_cancel_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE TRUE AND  shortwait_cancel_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_cancel_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 5 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_cancel_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*257586<1000 AND  mediumwait_cancel_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_cancel_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 5 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_cancel_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*1030924<1000 AND  largewait_cancel_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_cancel_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 6 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_match_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*5923272<1000 AND  shortwait_match_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_match_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 6 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_match_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*5117429<1000 AND  mediumwait_match_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_match_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 7 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_match_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*1297762<1000 AND  largewait_match_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_match_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 7 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_lapse_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*2192<1000 AND  shortwait_lapse_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_lapse_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 8 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_lapse_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*8144<1000 AND  mediumwait_lapse_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_lapse_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 8 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_lapse_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*1820172<1000 AND  largewait_lapse_small_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_lapse_small_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 9 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_cancel_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE TRUE AND  shortwait_cancel_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_cancel_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 9 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_cancel_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*58765<1000 AND  mediumwait_cancel_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_cancel_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 10 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_cancel_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*1027391<1000 AND  largewait_cancel_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_cancel_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 10 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_match_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*4200562<1000 AND  shortwait_match_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_match_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 11 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_match_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*6684824<1000 AND  mediumwait_match_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_match_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 11 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_match_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*7860864<1000 AND  largewait_match_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_match_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 12 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_lapse_large_expectation_missed' AS _treatment, 0 AS _p FROM __temp_table WHERE FALSE AND  shortwait_lapse_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'shortwait_lapse_large_expectation_missed' AS _treatment, 0 AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 12 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_lapse_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE TRUE AND  mediumwait_lapse_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'mediumwait_lapse_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 13 and ride_id is not null union all \n",
      "SELECT *, 1 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_lapse_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE _rand*938052<1000 AND  largewait_lapse_large_expectation_missed=1 and ride_id is not null union all \n",
      "SELECT *, 0 AS _type,rand(0)<0.2 AS _test, CAST(rand(0)*4 AS int) AS _fold, 'largewait_lapse_large_expectation_missed' AS _treatment, CAST(rand(0)*0 AS int) AS _p FROM __temp_table WHERE FALSE AND  shortwait_match_no_expectation_missed = 13 and ride_id is not null\n",
      "Traceback (most recent call last):\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\", line 72, in _run\n",
      "    self.execute()\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 52, in execute\n",
      "    self.execute_with_dfs(self.get_dfs())\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 515, in execute_with_dfs\n",
      "    lambda: self.process(dfs), \".parquet\", repartition=False, partition_by=False\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 180, in read_or_cache\n",
      "    df = self.handle_persist(df)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 210, in handle_persist\n",
      "    return self.execution_engine().persist(df, None)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_spark/execution.py\", line 110, in persist\n",
      "    ct = df.count()  # force to happen\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_spark/dataframe.py\", line 75, in count\n",
      "    self.__spark_df_count = self.df.count()\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/dataframe.py\", line 664, in count\n",
      "    return int(self._jdf.count())\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o9852.count.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 10.0 failed 4 times, most recent failure: Lost task 17.3 in stage 10.0 (TID 17481) (10.44.14.89 executor 45): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/worker.py\", line 596, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/serializers.py\", line 259, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 660, in mapPartition\n",
      "    raise e\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 653, in mapPartition\n",
      "    res = self.transformer.transform(c)\n",
      "  File \"/mnt/user-home/git/nesdatapipeline/nesdatapipeline/transform.py\", line 60, in transform\n",
      "    subschema = df.schema.extract(cols)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/schema.py\", line 108, in extract\n",
      "    s.append(self.names[x], self.types[x])\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/schema.py\", line 159, in append\n",
      "    raise ValueError(\"Invalid column name \" + key)\n",
      "ValueError: Invalid column name shortwait_cancel_small_expectation_missed_r7\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/worker.py\", line 596, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/serializers.py\", line 259, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 660, in mapPartition\n",
      "    raise e\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 653, in mapPartition\n",
      "    res = self.transformer.transform(c)\n",
      "  File \"/mnt/user-home/git/nesdatapipeline/nesdatapipeline/transform.py\", line 60, in transform\n",
      "    subschema = df.schema.extract(cols)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/schema.py\", line 108, in extract\n",
      "    s.append(self.names[x], self.types[x])\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/schema.py\", line 159, in append\n",
      "    raise ValueError(\"Invalid column name \" + key)\n",
      "ValueError: Invalid column name shortwait_cancel_small_expectation_missed_r7\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1423)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1350)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1414)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1237)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "('Failed ______2', Py4JJavaError('An error occurred while calling o9852.count.\\n', JavaObject id=o9855))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1067fbfd87ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mds_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2021-02-03'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mds_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2021-02-28'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     fold = EVALUATION_FOLD, sample_ratio=0.5,seed=0)\n\u001b[0m",
      "\u001b[0;32m/mnt/user-home/git/nesdatapipeline/nesdatapipeline/tasks.py\u001b[0m in \u001b[0;36mprepare_samples\u001b[0;34m(run, sample_size, path, treatment_group_config, ds_from, ds_to, continuous_features, target_features, onehot_features, table, label, test_pct, fold, partition_size, seed, sample_ratio)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\", sample_size=sample_size, path=path,\n\u001b[1;32m     60\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment_group_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtreatment_group_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0monehot_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monehot_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         partition_size=partition_size, fold=fold, test_pct=test_pct, seed=seed, sample_ratio=sample_ratio)\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_sql/run.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, code, *dicts, **macros)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmacros\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     ) -> WorkflowYieldCollection:\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmacros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_sql/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, *dicts, **macros)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fugue.dag.sequential\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, execution_engine, sequential, throw)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, throw)\u001b[0m\n\u001b[1;32m    211\u001b[0m                         \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed {k}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                         \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, throw)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             self.output.fail_all(\n\u001b[1;32m     74\u001b[0m                 \u001b[0mDependencyException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dependency not fulfilled by {self}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_with_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     def compile_into(\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36mexecute_with_dfs\u001b[0;34m(self, dfs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_with_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         self.output[\"__output\"] = self.read_or_cache(\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         )\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36mread_or_cache\u001b[0;34m(self, func, name_suffix, repartition, partition_by, persist, broadcast)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_repartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_persist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36mhandle_persist\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpersist\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_spark/execution.py\u001b[0m in \u001b[0;36mpersist\u001b[0;34m(self, orig_df, level)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# force to happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Persist dataframe with default level, count {ct}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persisted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_spark/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self, persist)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spark_df_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spark_df_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \"\"\"\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ('Failed ______2', Py4JJavaError('An error occurred while calling o9852.count.\\n', JavaObject id=o9855))"
     ]
    }
   ],
   "source": [
    "with LLK8sRunner(SPARK_CONFIG_SAMPLING, {\"spark.dynamicAllocation.maxExecutors\": 200,\"spark.eventLog.enabled\":\"false\",\"spark.eventLog.dir\":\"\",},) as run:\n",
    "    prepare_samples(run, \n",
    "                    sample_size=TRAINING_SAMPLE_SIZE, \n",
    "                    path=TRAINING_DATA_PATH, \n",
    "                    treatment_group_config=treatment_group_config_path,  \n",
    "                    continuous_features=continuous_features,\n",
    "                    target_features=target_features,\n",
    "                    onehot_features=onehot_features,\n",
    "                    label='ride_dropoffs_f28',\n",
    "                    table=SAMPLING_SOURCE_TABLE,\n",
    "                    test_pct=EVALUATION_TEST_PCT,\n",
    "                    ds_from='2021-02-03',\n",
    "                    ds_to='2021-02-28',\n",
    "                    fold = EVALUATION_FOLD, sample_ratio=0.5,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"*method\": [\"TLearner\"], \"*max_depth\": [2, 3, 5], \"*n_estimators\": [5, 10, 20]}\n",
      "Traceback (most recent call last):\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\", line 72, in _run\n",
      "    self.execute()\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 52, in execute\n",
      "    self.execute_with_dfs(self.get_dfs())\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 546, in execute_with_dfs\n",
      "    lambda: self._execute_with_dfs(dfs), repartition=False, partition_by=False\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 169, in read_or_cache\n",
      "    df = self.execution_engine().to_df(func())\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 546, in <lambda>\n",
      "    lambda: self._execute_with_dfs(dfs), repartition=False, partition_by=False\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\", line 569, in _execute_with_dfs\n",
      "    ignore_errors=ignore,\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 464, in estimate\n",
      "    result, selector, partition_keys=mt_pk, parameters=parameters\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 277, in run_transformer\n",
      "    partitioner=partitioner,\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_spark/execution.py\", line 304, in map_partitions\n",
      "    result = sdf.native().rdd.mapPartitionsWithIndex(mapFunc, True)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/dataframe.py\", line 85, in rdd\n",
      "    jrdd = self._jdf.javaToPython()\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o7772.javaToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: \n",
      "Aborting TaskSet 20.0 because task 215 (partition 215)\n",
      "cannot run anywhere due to node and executor excludeOnFailure.\n",
      "Most recent failure:\n",
      "Lost task 209.1 in stage 20.0 (TID 10886) (10.44.186.41 executor 4): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/worker.py\", line 596, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pyspark/serializers.py\", line 259, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 717, in mapPartition\n",
      "    raise e\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\", line 710, in mapPartition\n",
      "    df = self.transformer.transform(self.dfs)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/transformers.py\", line 410, in transform\n",
      "    output = self.fit(dfs)\n",
      "  File \"/mnt/user-home/git/nesdatapipeline/nesdatapipeline/ml.py\", line 86, in fit\n",
      "    n.generate_propensity_scores()\n",
      "  File \"/mnt/user-home/git/nes/nes/model/metalearner.py\", line 194, in generate_propensity_scores\n",
      "    self.split_X_y()\n",
      "  File \"/mnt/user-home/git/nes/nes/model/metalearner.py\", line 147, in split_X_y\n",
      "    self.x_train = self.train[self.cols]\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2912, in __getitem__\n",
      "    indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1254, in _get_listlike_indexer\n",
      "    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n",
      "  File \"/code/venvs/venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1304, in _validate_read_indexer\n",
      "    raise KeyError(f\"{not_found} not in index\")\n",
      "KeyError: \"['shortwait_cancel_large_expectation_missed_r14', 'largewait_cancel_large_expectation_missed_r14', 'mediumwait_match_large_expectation_missed_r14', 'largewait_match_small_expectation_missed_r14', 'shortwait_lapse_small_expectation_missed_r7', 'largewait_cancel_large_expectation_missed_r7', 'mediumwait_cancel_large_expectation_missed_r28', 'shortwait_match_small_expectation_missed_r7', 'mediumwait_cancel_small_expectation_missed_r14', 'mediumwait_match_no_expectation_missed_r28', 'largewait_lapse_large_expectation_missed_r14', 'shortwait_cancel_small_expectation_missed_r28', 'largewait_lapse_small_expectation_missed_r7', 'mediumwait_match_large_expectation_missed_r7', 'mediumwait_match_small_expectation_missed_r14', 'shortwait_match_small_expectation_missed_r28', 'shortwait_lapse_large_expectation_missed_r14', 'mediumwait_lapse_no_expectation_missed_r7', 'mediumwait_cancel_small_expectation_missed_r28', 'largewait_cancel_small_expectation_missed_r14', 'largewait_lapse_small_expectation_missed_r14', 'shortwait_match_large_expectation_missed_r14', 'shortwait_lapse_small_expectation_missed_r28', 'mediumwait_lapse_small_expectation_missed_r14', 'mediumwait_cancel_large_expectation_missed_r14', 'shortwait_match_small_expectation_missed_r14', 'shortwait_match_large_expectation_missed_r7', 'shortwait_cancel_large_expectation_missed_r7', 'shortwait_lapse_no_expectation_missed_r7', 'largewait_lapse_no_expectation_missed_r14', 'largewait_lapse_no_expectation_missed_r28', 'largewait_match_no_expectation_missed_r14', 'mediumwait_lapse_small_expectation_missed_r28', 'largewait_lapse_no_expectation_missed_r7', 'mediumwait_cancel_small_expectation_missed_r7', 'mediumwait_match_no_expectation_missed_r14', 'largewait_cancel_large_expectation_missed_r28', 'shortwait_match_no_expectation_missed_r14', 'mediumwait_lapse_large_expectation_missed_r7', 'largewait_match_small_expectation_missed_r7', 'mediumwait_lapse_no_expectation_missed_r14', 'largewait_cancel_no_expectation_missed_r14', 'shortwait_lapse_no_expectation_missed_r14', 'largewait_lapse_small_expectation_missed_r28', 'shortwait_lapse_large_expectation_missed_r28', 'largewait_cancel_small_expectation_missed_r7', 'mediumwait_match_small_expectation_missed_r7', 'largewait_match_no_expectation_missed_r28', 'shortwait_cancel_no_expectation_missed_r7', 'shortwait_match_no_expectation_missed_r28', 'shortwait_lapse_large_expectation_missed_r7', 'shortwait_lapse_no_expectation_missed_r28', 'mediumwait_lapse_no_expectation_missed_r28', 'shortwait_cancel_small_expectation_missed_r14', 'mediumwait_cancel_no_expectation_missed_r7', 'mediumwait_cancel_no_expectation_missed_r28', 'mediumwait_match_no_expectation_missed_r7', 'largewait_cancel_no_expectation_missed_r28', 'largewait_lapse_large_expectation_missed_r7', 'shortwait_lapse_small_expectation_missed_r14', 'shortwait_match_large_expectation_missed_r28', 'largewait_cancel_small_expectation_missed_r28', 'largewait_match_no_expectation_missed_r7', 'largewait_match_small_expectation_missed_r28', 'mediumwait_lapse_small_expectation_missed_r7', 'shortwait_match_no_expectation_missed_r7', 'largewait_lapse_large_expectation_missed_r28', 'mediumwait_lapse_large_expectation_missed_r28', 'shortwait_cancel_small_expectation_missed_r7', 'shortwait_cancel_no_expectation_missed_r28', 'mediumwait_lapse_large_expectation_missed_r14', 'largewait_cancel_no_expectation_missed_r7', 'mediumwait_match_small_expectation_missed_r28', 'mediumwait_cancel_no_expectation_missed_r14', 'mediumwait_cancel_large_expectation_missed_r7', 'shortwait_cancel_large_expectation_missed_r28', 'mediumwait_match_large_expectation_missed_r28', 'shortwait_cancel_no_expectation_missed_r14'] not in index\"\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:177)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\n",
      "ExcludeOnFailure behavior can be configured via spark.excludeOnFailure.*.\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "('Failed ___model___0', Py4JJavaError('An error occurred while calling o7772.javaToPython.\\n', JavaObject id=o7774))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c5b4cfb4fa2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TLearner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           n_estimators=[5,10,20])\n\u001b[0m",
      "\u001b[0;32m/mnt/user-home/git/nesdatapipeline/nesdatapipeline/tasks.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(run, data_path, model_path, metric_type, treatment_group_config, label, continuous_features, target_features, onehot_features, fold, **hp)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mOUTPUT\u001b[0m \u001b[0mTO\u001b[0m \u001b[0;34m\"{$model_path}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \"\"\", path=data_path, model_path = model_path,metric_type=metric_type,treatment_group_config=treatment_group_config,continuous_features=continuous_features,target_features=target_features,onehot_features=onehot_features,label=label,\n\u001b[0;32m--> 150\u001b[0;31m         hp=hp, folds=json.dumps(list(range(fold))))\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_sql/run.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, code, *dicts, **macros)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmacros\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     ) -> WorkflowYieldCollection:\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmacros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_sql/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, *dicts, **macros)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fugue.dag.sequential\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, execution_engine, sequential, throw)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, throw)\u001b[0m\n\u001b[1;32m    211\u001b[0m                         \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed {k}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                         \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/workflow.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, throw)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             self.output.fail_all(\n\u001b[1;32m     74\u001b[0m                 \u001b[0mDependencyException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dependency not fulfilled by {self}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_with_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     def compile_into(\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36mexecute_with_dfs\u001b[0;34m(self, dfs)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_with_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         self.output[\"model\"] = self.read_or_cache(\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_with_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         )\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36mread_or_cache\u001b[0;34m(self, func, name_suffix, repartition, partition_by, persist, broadcast)\u001b[0m\n\u001b[1;32m    167\u001b[0m     ) -> DataFrame:\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"persist\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"global\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_with_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         self.output[\"model\"] = self.read_or_cache(\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_with_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         )\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/tasks.py\u001b[0m in \u001b[0;36m_execute_with_dfs\u001b[0;34m(self, dfs)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mnum_partitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"repartition\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"partitioner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"even\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m         )\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\u001b[0m in \u001b[0;36mestimate\u001b[0;34m(self, dfs, estimator, hpc, vpc, join_type, selector, path, to_file_threshold, num_partitions, parameters, ignore_errors, partitioner)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# has model selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             result = self.run_transformer(\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmt_pk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             )\n\u001b[1;32m    466\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVALUATION_PARAMETER_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue/execution.py\u001b[0m in \u001b[0;36mrun_transformer\u001b[0;34m(self, df, transformer, num_partitions, partition_keys, presort, row_limit, size_limit, parameters, ignore_errors, partitioner)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mpartition_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mpresort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpresort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/lyft_fugue_spark/execution.py\u001b[0m in \u001b[0;36mmap_partitions\u001b[0;34m(self, df, mapFunc, output_schema, num_partitions, partition_keys, presort, partitioner)\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[1;32m    303\u001b[0m         )\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitionsWithIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \"\"\"\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_rdd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjavaToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_rdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_rdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ('Failed ___model___0', Py4JJavaError('An error occurred while calling o7772.javaToPython.\\n', JavaObject id=o7774))"
     ]
    }
   ],
   "source": [
    "with LLK8sRunner(SPARK_CONFIG_SAMPLING, {\"spark.dynamicAllocation.maxExecutors\": 200,\"spark.eventLog.enabled\":\"false\",\"spark.eventLog.dir\":\"\",},) as run:\n",
    "    train(run,\n",
    "          data_path =TRAINING_DATA_PATH,\n",
    "          model_path =MODEL_PATH,\n",
    "          metric_type='auuc',\n",
    "          treatment_group_config=treatment_group_config_path, \n",
    "          continuous_features=continuous_features,\n",
    "          target_features=target_features,\n",
    "          onehot_features=onehot_features,\n",
    "          label='ride_dropoffs_f28',\n",
    "          method=[\"TLearner\"],\n",
    "          max_depth=[2,3,5],\n",
    "          n_estimators=[5,10,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name='auuc'\n",
    "data=fsql_local(\"\"\"\n",
    "LOAD MODEL \"{$path}\"\n",
    "data:=\tSELECT treatment,__model_score__,__model_metadata__,\n",
    "CAST(get_json_object(__model_metadata__, '$.test_{$metric_name}') AS double) AS test_{$metric_name}\n",
    "YIELD data\n",
    "\"\"\", path=MODEL_PATH,metric_name=metric_name).data\n",
    "df = data.as_pandas()\n",
    "df[\"test_{0}\".format(metric_name)]=-1.0*df[\"test_{0}\".format(metric_name)]\n",
    "xdf = df[[\"treatment\",\"test_{0}\".format(metric_name)]]\n",
    "df.plot.bar(x='treatment', y=[\"test_{0}\".format(metric_name)], rot=80, figsize=(15,5))\n",
    "treatments=list(df['treatment'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Prepare samples for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LLK8sRunner(SPARK_CONFIG_SAMPLING, {\"spark.dynamicAllocation.maxExecutors\": 200,\"spark.eventLog.enabled\":\"false\",\"spark.eventLog.dir\":\"\",},) as run:\n",
    "    prepare_inference(run, \n",
    "                    output_path=PREDICTION_DATA_PATH, \n",
    "                    treatment_group_config=treatment_group_config_path,  ### use treatment_group_config_path instead\n",
    "                    backfill_days=20,\n",
    "                    label='ride_dropoffs_f28',\n",
    "                    continuous_features=continuous_features,\n",
    "                    target_features=target_features,\n",
    "                    onehot_features=onehot_features,\n",
    "                    ds='2021-01-28',\n",
    "                    table=SAMPLING_SOURCE_TABLE,\n",
    "                    test_pct=EVALUATION_TEST_PCT,\n",
    "                    fold = EVALUATION_FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Sanity check average estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments=list(df['treatment'].values)\n",
    "try:\n",
    "    print (\"removed control\")\n",
    "    treatments.remove('smallwait_match_no_expectation_missed')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "#treatments = ['post_actual_6_{0}'.format(t) for t in range(-4,4)]\n",
    "\n",
    "from lyft_fugue_lyft import fsql_local, fsql_k8s\n",
    "from lyft_fugue import ExecutionEngine, DataFrame\n",
    "from lyft_fugue_spark import SparkDataFrame\n",
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "for t in treatments:\n",
    "    data = fsql_k8s({\"fugue.cluster.size\":\"4*4*4g\"},\"\"\"\n",
    "    LOAD \"{$path}\"\n",
    "    data:=SELECT * WHERE treatment=='{$treatment}'\n",
    "    YIELD data\n",
    "    \"\"\", path = PREDICTION_OUTPUT_DATA_PATH+'/ds=2021-01-28/out.parquet',treatment=t).data\n",
    "\n",
    "    df = data.as_pandas()\n",
    "    score = df['score'].mean()\n",
    "    print (t,score)\n",
    "    scores.append(score)\n",
    "df_results=pd.DataFrame({'treatments':treatments,'score':scores})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
